{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for building the text pre-processing pipeline\n",
    "\n",
    "Rough outline of the pipeline:\n",
    "1. remove punctuation, numbers, capitalization from all text. Return full string rather than individual tokens\n",
    "2. replace alternatives/synonyms with a single token for that word\n",
    "3. isolate the key word of interest in case it appears in any hashtags\n",
    "4. label that token based on party affiliation\n",
    "5. remove stopwords, tokenize, lematize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "# import demoji\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode PrepDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPrep:\n",
    "    \"\"\"\n",
    "    Class for either tokenizing or lemmatizing a corpus of documents\n",
    "    \n",
    "    key_words is a list of words you're interested in locating in the text\n",
    "    \n",
    "    key_synonyms is meant to be a dictionary of synonyms and their associated key tokens.\n",
    "    This is helpful if used in conjunction with the replace_keyword method so that all\n",
    "    synonyms can be replaced by a single token.\n",
    "    \n",
    "    twitter_preprocess does basic cleaning for twitter text\n",
    "    \n",
    "    replace_keyword is used to replace synonyms with a single keyword\n",
    "    \n",
    "    tag_tokens will tag keywords found within a text with the appropriate label\n",
    "    \n",
    "    spacy_tokenizer and spacy_lemmatizer remove digits, punctuation, stopwords, and returns\n",
    "    either the token or lemma\n",
    "    \"\"\"\n",
    "    def __init__(self, model = 'en', stopwords = None, key_words = None, key_synonyms = None):\n",
    "        self.model = model\n",
    "        self.stopwords = stopwords\n",
    "        self.key_words = key_words\n",
    "        self.key_synonyms = key_synonyms\n",
    "    \n",
    "    def twitter_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        This functions does some preliminary cleaning for twitter text. it will:\n",
    "        1. Remove all pound symbols from text\n",
    "        2. If key_words is defined, isolate key words from hashtags so they can be treated as individual tokens\n",
    "        3. Remove emoji\n",
    "        4. Remove websites from the text\n",
    "        5. Convert to lower case\n",
    "        \"\"\"\n",
    "        # remove pound signs\n",
    "        #text = re.sub('#', '', text)\n",
    "        # remnove @ symbol\n",
    "        #text = re.sub('@', '', text)\n",
    "        # remove websites\n",
    "        text = re.sub('https:\\S*', '', text)\n",
    "        # remove all punctuation and digits\n",
    "        text = re.sub('[^\\w\\s_]|_|\\d','',text)\n",
    "        # remove excess white space between words\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        # remove leading and trailing white space\n",
    "        text = text.strip()\n",
    "        # convert to lower case\n",
    "        text = text.lower()\n",
    "        # remove emoji, commented out because regular expressions remove them currently\n",
    "        #text = demoji.replace(text, '')\n",
    "        return text\n",
    "        \n",
    "    def replace_synonyms(self, keyword, text):\n",
    "        \"\"\"\n",
    "        Called by the tag_keywords method.\n",
    "        \n",
    "        Uses the key_synonyms dictionary to locate synonyms and\n",
    "        replace them with their associated key word. Will not work\n",
    "        if the key word is not found in the key_synonyms dictionary\n",
    "        \"\"\"\n",
    "        # subset key words dictionary to only those with the selected key word\n",
    "        dictionary = {key:value for key, value in self.key_synonyms.items() if value == keyword}\n",
    "        # Create a regular expression  from the dictionary keys\n",
    "        regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dictionary.keys())))\n",
    "        # For each match, look-up corresponding value in dictionary\n",
    "        return regex.sub(lambda mo: dictionary[mo.string[mo.start():mo.end()]], text)\n",
    "    \n",
    "    def tag_keywords(self, keyword, text, tag):\n",
    "        \"\"\"\n",
    "        Finds all instances of a user defined token within a specific corpus and tags it to\n",
    "        a specific group. Pass a list of text documents, and a list of associated tags for those documents\n",
    "        such as two columns from a data frame. \n",
    "        \"\"\"\n",
    "        # replace synonyms of the key words with the key word\n",
    "        text = self.replace_synonyms(keyword, text)\n",
    "        # isolate the key word with space so it can be treated as an individual token\n",
    "        text = re.sub(keyword, ' ' + keyword + ' ', text)\n",
    "        # Add the group label\n",
    "        text = re.sub(keyword, keyword + \"_\" + tag, text)\n",
    "        # eliminate excess whitespace created\n",
    "        text = re.sub('\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def spacy_tokenizer(self, text):\n",
    "        \"\"\"\n",
    "        Called by the clean_file method\n",
    "        Tokenizes, returns lower case, removes stop words and punctuation,\n",
    "        \"\"\"\n",
    "        nlp = spacy.load(self.model, disabled = ['tagger', 'parser', 'ner', 'textcat'])\n",
    "        # tokenize\n",
    "        text = self.nlp(text)\n",
    "        # take the token unless it is a stopword\n",
    "        text = [token.text.lower().strip() for token in text if not token.is_stop]\n",
    "        return text\n",
    "\n",
    "    def spacy_lemmatizer(self, text):\n",
    "        \"\"\"\n",
    "        Called by the lemmatize_file method\n",
    "        Tokenizes, lemmatizes, returns lower case, removes stop words and punctuation\n",
    "        \"\"\"\n",
    "        # reload spacy with pat of speech tagger\n",
    "        nlp = spacy.load(self.model, disable = ['parser', 'ner', 'textcat'])\n",
    "        # tokenize\n",
    "        text = nlp(text)\n",
    "        # take the lemma unless it is a stopword\n",
    "        text = [token.lemma_.lower().strip() for token in text if not token.is_stop]\n",
    "        return text\n",
    "    \n",
    "    def multi_lemmatizer(self, text_list, threads):\n",
    "        \"\"\"\n",
    "        Called by the lemmatize_file method\n",
    "        Tokenizes, lemmatizes, returns lower case, removes stop words and punctuation\n",
    "        \"\"\"\n",
    "        # reload spacy with pat of speech tagger\n",
    "        nlp = spacy.load(self.model, disable = ['parser', 'ner', 'textcat'])\n",
    "        \n",
    "        text_lemmas = []\n",
    "        for text in nlp.pipe(text_list, n_threads = threads):\n",
    "            tokens = [token.lemma_.lower().strip() for token in text if not token.is_stop]\n",
    "            text_lemmas.append(tokens)\n",
    "        return text_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(self, text):\n",
    "    text = re.sub('#', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert spaces between key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_keyword(self, word, text):\n",
    "    text = re.sub(word, ' ' + word + ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key word dicitonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# a list of all key tokens\n",
    "key_tokens = ['trump',\n",
    "'president',\n",
    "'healthcare',\n",
    "'border',\n",
    "'wall',\n",
    "'democrat',\n",
    "'republican',\n",
    "'liberal',\n",
    "'conservative',\n",
    "'abortion',\n",
    "'clinton',\n",
    "'sanders',\n",
    "'socialist',\n",
    "'economy',\n",
    "'jobs',\n",
    "'impeach',\n",
    "'obama',\n",
    "'russia',\n",
    "'mueller',\n",
    "'collusion',\n",
    "'military',\n",
    "'budget',\n",
    "'market',\n",
    "'trade',\n",
    "'vote',\n",
    "'democracy',\n",
    "'gun',\n",
    "'agriculture',\n",
    "'women',\n",
    "'business',\n",
    "'tax',\n",
    "'medicare',\n",
    "'police',\n",
    "'immigration',\n",
    "'insurance',\n",
    "'climatechange',\n",
    "'corrupt',\n",
    "'electoralcollege',\n",
    "'judge',\n",
    "'court',\n",
    "'gerrymander',\n",
    "'pelosi',\n",
    "'mcconnell',\n",
    "'mikepence',\n",
    "'citizensunited',\n",
    "'daca',\n",
    "'dreamers',\n",
    "'lgbtq',\n",
    "'ACA',\n",
    "'scotus',\n",
    "'partisan',\n",
    "'patriot',\n",
    "'welfare',\n",
    "'privilege',\n",
    "'minority',\n",
    "'islam',\n",
    "'muslim',\n",
    "'christian',\n",
    "'god',\n",
    "'religion',\n",
    "'administration',\n",
    "'politics',\n",
    "'fair',\n",
    "'witchhunt',\n",
    "'warren',\n",
    "'biden',\n",
    "'security',\n",
    "'terrorism',\n",
    "'defense',\n",
    "'pentagon',\n",
    "'homelandsecurity',\n",
    "'senate',\n",
    "'wealth',\n",
    "'american',\n",
    "'church',\n",
    "'science',\n",
    "'stockmarket',\n",
    "'congress',\n",
    "'whitehouse',\n",
    "'constitution',\n",
    "'federal',\n",
    "'syria',\n",
    "'northkorea',\n",
    "'saudiarabia',\n",
    "'mexico',\n",
    "'debt',\n",
    "'fiscal',\n",
    "'oil',\n",
    "'media',\n",
    "'cnn',\n",
    "'fox',\n",
    "'news',\n",
    "'racist',\n",
    "'refugee',\n",
    "'education',\n",
    "'maga',\n",
    "'campaign',\n",
    "'party',\n",
    "'poll']\n",
    "\n",
    "f = open(\"Meta Data/key_tokens.pkl\",\"wb\")\n",
    "pickle.dump(key_tokens,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald trump\n",
      "president trump\n"
     ]
    }
   ],
   "source": [
    "# returns the synonyms for each key token\n",
    "for key, token in key_synonyms.items():\n",
    "    if token == key_tokens[0]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# this dicitonary can be used to replace key word synonyms with a single token\n",
    "# get a list of the keys relevant, pass to the replace_keyword function\n",
    "\n",
    "key_synonyms = {\n",
    "    'realdonaldtrump': 'trump',\n",
    "    'realdonald trump': 'trump',\n",
    "    'donaldtrump': 'trump',\n",
    "    'donald trump': 'trump',\n",
    "    'presidenttrump': 'trump',\n",
    "    'president trump': 'trump',\n",
    "    'potus': 'trump',\n",
    "    'health care': 'healthcare',\n",
    "    'dems': 'democrat',\n",
    "    'gop': 'republican',\n",
    "    'left wing': 'liberal',\n",
    "    'leftist': 'liberal',\n",
    "    'progressive': 'liberal',\n",
    "    'right wing': 'conservative',\n",
    "    'abort': 'abortion',\n",
    "    'bernie sanders': 'sanders',\n",
    "    'bernie': 'sanders',\n",
    "    ' econ ': ' economy ',\n",
    "    'economics': 'economy',\n",
    "    'impeachment': 'impeach',\n",
    "    'barack obama': 'obama',\n",
    "    'robert mueller': 'mueller',\n",
    "    'armed forces': 'military',\n",
    "    'armed services': 'military',\n",
    "    'firearm': 'gun',\n",
    "    'assault rifle': 'gun',\n",
    "    'climate change': 'climatechange',\n",
    "    'global warming': 'climatechange',\n",
    "    'corruption': 'corrupt',\n",
    "    'corrupted': 'corrupt',\n",
    "    'electoral college': 'electoralcollege',\n",
    "    'court justice': 'judge',\n",
    "    'nancy pelosi': 'pelosi',\n",
    "    'mitch mcconnell': 'mcconnell',\n",
    "    'vice president mike pence': 'mikepence',\n",
    "    'vice president pence' : 'mikepence',\n",
    "    'mike pence': 'mikepence',\n",
    "    ' pence ': ' mikepence ',\n",
    "    'citizens united': 'citizensunited',\n",
    "    'deferred action for childhood arrivals': 'daca',\n",
    "    'lgbt': 'lgbtq',\n",
    "    'affordable care act': 'aca',\n",
    "    'obamacare': 'aca',\n",
    "    'obama care': 'aca',\n",
    "    'supreme court of the united states': 'scotus',\n",
    "    'us supreme court': 'scotus',\n",
    "    'united states supreme court': 'scotus',\n",
    "    'supreme court': 'scotus',\n",
    "    'islamic': 'islam',\n",
    "    'christianity': ' christian',\n",
    "    'political': 'politics',\n",
    "    'witch hunt': 'witchhunt',\n",
    "    'elizabeth warren': 'warren',\n",
    "    'counterterrorism': 'terrorism',\n",
    "    'counter-terrorism': 'terrorism',\n",
    "    'homeland security': 'homelandsecurity',\n",
    "    'us senate': 'senate',\n",
    "    'united states senate': 'senate',\n",
    "    'senatorial': 'senate',\n",
    "    'rich': 'wealthy',\n",
    "    'wealthy': ' wealth',\n",
    "    'billionaire': 'wealthy',\n",
    "    'temple': 'church',\n",
    "    'stock market': 'stockmarket',\n",
    "    'stocks': 'stockmarket',\n",
    "    'congressional': 'congress',\n",
    "    'white house': 'whitehouse',\n",
    "    'north korean': 'northkorea',\n",
    "    'north korea': 'northkorea',\n",
    "    'saudi arabian': 'saudiarabia',\n",
    "    'saudi arabia': 'saudiarabia',\n",
    "    ' saudi ': ' saudiarabia ',\n",
    "    'mexican': 'mexico',\n",
    "    'fox news': 'fox',\n",
    "    'cable news network': 'cnn',\n",
    "    'make america great again': 'maga'\n",
    "}\n",
    "\n",
    "f = open(\"Meta Data/synonym_dictionary.pkl\",\"wb\")\n",
    "pickle.dump(key_synonyms,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_keyword(token, replacement, text):\n",
    "    text = re.sub(token, replacement, text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'president donald trump is an american hero'\n",
    "for key in list(key_words)[0:2]:\n",
    "    text = replace_keywords(key, key_words[key], text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short list of stopwords, does not deal with contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['i','a', 'about', 'am', 'an', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'how', 'in', 'is', 'it', 'of', 'on', 'or', 'that', \n",
    "             'the', 'this', 'to', 'was', 'what', 'when', 'where', 'who', 'will', 'with', 'the']\n",
    "\n",
    "f = open(\"Meta Data/stopwords.pkl\",\"wb\")\n",
    "pickle.dump(stopwords,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â€˜re',\n",
       " 'formerly',\n",
       " 'everything',\n",
       " 'while',\n",
       " 'eleven',\n",
       " 'enough',\n",
       " \"'ll\",\n",
       " 'am',\n",
       " 'seeming',\n",
       " \"n't\",\n",
       " 'hence',\n",
       " 'will',\n",
       " 'did',\n",
       " 'ever',\n",
       " 'make',\n",
       " 'with',\n",
       " 'i',\n",
       " 'whoever',\n",
       " 'what',\n",
       " 'whenever',\n",
       " 'noone',\n",
       " 'where',\n",
       " 'anyway',\n",
       " 'after',\n",
       " 'unless',\n",
       " 'nâ€˜t',\n",
       " 'everyone',\n",
       " 'done',\n",
       " 'then',\n",
       " 'each',\n",
       " 'whereafter',\n",
       " 'show',\n",
       " 'any',\n",
       " 'so',\n",
       " 'she',\n",
       " 'that',\n",
       " 'out',\n",
       " 'always',\n",
       " 'meanwhile',\n",
       " 'next',\n",
       " 'an',\n",
       " 'elsewhere',\n",
       " 'nobody',\n",
       " 'few',\n",
       " 'could',\n",
       " 'therein',\n",
       " 'does',\n",
       " 'front',\n",
       " 'himself',\n",
       " 'were',\n",
       " 'thereby',\n",
       " 'such',\n",
       " 'seems',\n",
       " 'or',\n",
       " 'yours',\n",
       " 'beside',\n",
       " 'another',\n",
       " 'quite',\n",
       " 'and',\n",
       " 'name',\n",
       " 'those',\n",
       " 'do',\n",
       " 'however',\n",
       " 'except',\n",
       " 'until',\n",
       " 'â€™m',\n",
       " 'sixty',\n",
       " 'ca',\n",
       " 'of',\n",
       " 'â€˜s',\n",
       " 'indeed',\n",
       " 'together',\n",
       " 'many',\n",
       " 'moreover',\n",
       " 'they',\n",
       " 'around',\n",
       " \"'re\",\n",
       " 'â€™s',\n",
       " 'too',\n",
       " 'under',\n",
       " 'via',\n",
       " 'toward',\n",
       " 'anyhow',\n",
       " 'therefore',\n",
       " 'hereupon',\n",
       " 'been',\n",
       " 'â€˜m',\n",
       " 'amongst',\n",
       " 'should',\n",
       " 'side',\n",
       " 'hers',\n",
       " 'hereby',\n",
       " 'several',\n",
       " 'when',\n",
       " 'anyone',\n",
       " 'namely',\n",
       " 'one',\n",
       " 'your',\n",
       " 'please',\n",
       " 'nothing',\n",
       " 'otherwise',\n",
       " 'here',\n",
       " 'sometimes',\n",
       " 'within',\n",
       " 'own',\n",
       " 'cannot',\n",
       " 'wherever',\n",
       " 'there',\n",
       " 'forty',\n",
       " 'over',\n",
       " 'former',\n",
       " 'used',\n",
       " 'anywhere',\n",
       " 'him',\n",
       " 'both',\n",
       " 'using',\n",
       " 'due',\n",
       " 'give',\n",
       " 'doing',\n",
       " 'all',\n",
       " 'often',\n",
       " 'you',\n",
       " 'something',\n",
       " 'less',\n",
       " 'eight',\n",
       " \"'m\",\n",
       " 'just',\n",
       " 'has',\n",
       " 'through',\n",
       " 'into',\n",
       " 'us',\n",
       " 'about',\n",
       " 'amount',\n",
       " 'â€™ll',\n",
       " 'others',\n",
       " 'along',\n",
       " 'throughout',\n",
       " 'regarding',\n",
       " 'although',\n",
       " 'call',\n",
       " 'being',\n",
       " 'else',\n",
       " 'â€˜ll',\n",
       " 'rather',\n",
       " 'itself',\n",
       " 'per',\n",
       " 'between',\n",
       " 'these',\n",
       " 'herein',\n",
       " 'whole',\n",
       " 'still',\n",
       " 'as',\n",
       " 'well',\n",
       " 'whatever',\n",
       " 'be',\n",
       " 'whereas',\n",
       " 'can',\n",
       " 'above',\n",
       " 'seem',\n",
       " 'becoming',\n",
       " 'ten',\n",
       " 'but',\n",
       " 'become',\n",
       " 'at',\n",
       " 'almost',\n",
       " 'three',\n",
       " 're',\n",
       " 'below',\n",
       " 'whether',\n",
       " 'how',\n",
       " 'third',\n",
       " 'ourselves',\n",
       " 'other',\n",
       " 'them',\n",
       " 'also',\n",
       " 'their',\n",
       " 'seemed',\n",
       " 'me',\n",
       " 'same',\n",
       " 'yourself',\n",
       " 'may',\n",
       " 'against',\n",
       " 'last',\n",
       " 'thereupon',\n",
       " 'empty',\n",
       " 'why',\n",
       " 'thus',\n",
       " 'alone',\n",
       " 'hereafter',\n",
       " 'was',\n",
       " 'bottom',\n",
       " 'hundred',\n",
       " 'the',\n",
       " 'afterwards',\n",
       " 'now',\n",
       " 'themselves',\n",
       " 'its',\n",
       " 'nowhere',\n",
       " 'â€˜d',\n",
       " 'some',\n",
       " 'fifteen',\n",
       " 'least',\n",
       " 'everywhere',\n",
       " 'say',\n",
       " 'see',\n",
       " 'among',\n",
       " 'again',\n",
       " 'whence',\n",
       " 'yet',\n",
       " 'ours',\n",
       " 'every',\n",
       " 'not',\n",
       " 'on',\n",
       " 'â€™re',\n",
       " 'by',\n",
       " 'â€™ve',\n",
       " 'a',\n",
       " 'we',\n",
       " 'thru',\n",
       " 'four',\n",
       " 'full',\n",
       " 'nor',\n",
       " 'myself',\n",
       " 'somehow',\n",
       " 'in',\n",
       " \"'d\",\n",
       " 'â€™d',\n",
       " 'whither',\n",
       " 'without',\n",
       " 'herself',\n",
       " 'his',\n",
       " 'various',\n",
       " 'it',\n",
       " 'either',\n",
       " 'neither',\n",
       " 'had',\n",
       " 'sometime',\n",
       " 'more',\n",
       " 'mostly',\n",
       " 'back',\n",
       " 'off',\n",
       " 'across',\n",
       " 'mine',\n",
       " 'to',\n",
       " 'my',\n",
       " 'became',\n",
       " 'her',\n",
       " 'beyond',\n",
       " 'take',\n",
       " 'which',\n",
       " 'upon',\n",
       " 'top',\n",
       " 'yourselves',\n",
       " 'go',\n",
       " 'latter',\n",
       " 'even',\n",
       " 'might',\n",
       " 'who',\n",
       " 'once',\n",
       " 'must',\n",
       " 'nine',\n",
       " 'five',\n",
       " 'anything',\n",
       " 'are',\n",
       " 'really',\n",
       " 'six',\n",
       " 'because',\n",
       " 'someone',\n",
       " 'is',\n",
       " 'get',\n",
       " 'somewhere',\n",
       " 'two',\n",
       " 'becomes',\n",
       " 'whereupon',\n",
       " 'very',\n",
       " 'keep',\n",
       " 'never',\n",
       " 'move',\n",
       " 'serious',\n",
       " 'thence',\n",
       " 'up',\n",
       " 'no',\n",
       " 'down',\n",
       " 'twenty',\n",
       " 'though',\n",
       " 'he',\n",
       " 'for',\n",
       " 'perhaps',\n",
       " 'if',\n",
       " 'whose',\n",
       " 'nevertheless',\n",
       " 'since',\n",
       " 'behind',\n",
       " 'from',\n",
       " 'only',\n",
       " 'much',\n",
       " 'latterly',\n",
       " 'twelve',\n",
       " 'â€˜ve',\n",
       " \"'s\",\n",
       " 'none',\n",
       " 'wherein',\n",
       " 'nâ€™t',\n",
       " \"'ve\",\n",
       " 'further',\n",
       " 'before',\n",
       " 'would',\n",
       " 'than',\n",
       " 'first',\n",
       " 'during',\n",
       " 'have',\n",
       " 'besides',\n",
       " 'most',\n",
       " 'made',\n",
       " 'this',\n",
       " 'our',\n",
       " 'beforehand',\n",
       " 'onto',\n",
       " 'whom',\n",
       " 'fifty',\n",
       " 'put',\n",
       " 'already',\n",
       " 'towards',\n",
       " 'thereafter',\n",
       " 'whereby']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longer list. spacy's default list of stop words minus a few key terms that may be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "# Stop words\n",
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "a about after afterwards again all almost\n",
    "already also although always am among amongst amount an and another any anyhow\n",
    "anyone anything anyway anywhere are around as at\n",
    "\n",
    "be became because become becomes becoming been before beforehand\n",
    "being beside besides beyond both bottom but by\n",
    "\n",
    "can cannot ca could\n",
    "\n",
    "did do does doing done down during\n",
    "\n",
    "each eight either eleven else elsewhere empty enough even ever every\n",
    "everyone everything everywhere except\n",
    "\n",
    "few fifteen fifty first five for former formerly forty four from front full\n",
    "further\n",
    "\n",
    "get go\n",
    "\n",
    "had has have he hence her here hereafter hereby herein hereupon hers herself\n",
    "him himself his how however hundred\n",
    "\n",
    "i if in indeed into is it its itself\n",
    "\n",
    "last latter latterly least less\n",
    "\n",
    "many may me meanwhile might mine more moreover most mostly move much\n",
    "must my myself\n",
    "\n",
    "name namely neither nevertheless next nine no nobody none noone nor not\n",
    "nothing now nowhere\n",
    "\n",
    "of off often on once one only onto or other others otherwise our ours ourselves\n",
    "out over own\n",
    "\n",
    "part per perhaps please put\n",
    "\n",
    "quite\n",
    "\n",
    "rather re really regarding\n",
    "\n",
    "same say see seem seemed seeming seems serious several she should show side\n",
    "since six sixty so some somehow someone something sometime sometimes somewhere\n",
    "still such\n",
    "\n",
    "take ten than that the their them themselves then thence there thereafter\n",
    "thereby therefore therein thereupon these they third this those though three\n",
    "through throughout thru thus to together too top toward towards twelve twenty\n",
    "two\n",
    "\n",
    "under until up unless upon used using\n",
    "\n",
    "various very very via was we well were what whatever when whence whenever where\n",
    "\n",
    "whereafter whereas whereby wherein whereupon wherever whether which while\n",
    "whither who whoever whole whom whose why will with within without would\n",
    "\n",
    "yet you your yours yourself yourselves\n",
    "\"\"\".split()\n",
    ")\n",
    "\n",
    "contractions = [\"n't\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\"]\n",
    "STOP_WORDS.update(contractions)\n",
    "\n",
    "for apostrophe in [\"â€˜\", \"â€™\"]:\n",
    "    for stopword in contractions:\n",
    "        STOP_WORDS.add(stopword.replace(\"'\", apostrophe))\n",
    "        \n",
    "f = open(\"Meta Data/stopwords.pkl\",\"wb\")\n",
    "pickle.dump(STOP_WORDS,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Lemmas of key tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>constitution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>syria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>north korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>saudi arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>gop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>fiscal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>refugee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>maga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>poll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "80  constitution\n",
       "81       federal\n",
       "82         syria\n",
       "83   north korea\n",
       "84  saudi arabia\n",
       "85           gop\n",
       "86        mexico\n",
       "87          debt\n",
       "88        fiscal\n",
       "89           oil\n",
       "90         media\n",
       "91          news\n",
       "92        racist\n",
       "93       refugee\n",
       "94     education\n",
       "95          maga\n",
       "96         mitch\n",
       "97      campaign\n",
       "98         party\n",
       "99          poll"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv('Political terms.csv', header = None)\n",
    "terms.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump\n",
      "president\n",
      "healthcare\n",
      "border\n",
      "wall\n",
      "democrat\n",
      "republican\n",
      "liberal\n",
      "conservative\n",
      "abortion abort\n",
      "clinton\n",
      "sander\n",
      "socialist\n",
      "economy\n",
      "job\n",
      "impeachment\n",
      "potus\n",
      "obama\n",
      "russia\n",
      "mueller\n",
      "collusion\n",
      "military\n",
      "budget\n",
      "market\n",
      "trade\n",
      "vote\n",
      "democracy\n",
      "gun\n",
      "firearm\n",
      "assualt rifle\n",
      "agriculture\n",
      "woman\n",
      "business\n",
      "tax\n",
      "medicare\n",
      "police\n",
      "immigration\n",
      "insurance\n",
      "climate\n",
      "corrupt\n",
      "progressive\n",
      "electoral college\n",
      "judge\n",
      "court\n",
      "gerrymander\n",
      "pelosi\n",
      "mcconnell\n",
      "penny\n",
      "citizen unite\n",
      "dreamer\n",
      "lgbtq\n",
      "obamacare\n",
      "scotus\n",
      "partisan\n",
      "patriot\n",
      "welfare\n",
      "privilege\n",
      "minority\n",
      "muslim\n",
      "god\n",
      "religion\n",
      "administration\n",
      "politic\n",
      "\n",
      "fair\n",
      "witch hunt\n",
      "warren\n",
      "biden\n",
      "security\n",
      "terrorism\n",
      "pentagon\n",
      "senate\n",
      "rich\n",
      "american\n",
      "church\n",
      "science\n",
      "supreme court\n",
      "stock\n",
      "congress\n",
      "white house\n",
      "constitution\n",
      "federal\n",
      "syria\n",
      "north korea\n",
      "saudi arabia\n",
      "gop\n",
      "mexico\n",
      "debt\n",
      "fiscal\n",
      "oil\n",
      "medium\n",
      "news\n",
      "racist\n",
      "refugee\n",
      "education\n",
      "maga\n",
      "mitch\n",
      "campaign\n",
      "party\n",
      "poll\n"
     ]
    }
   ],
   "source": [
    "for i in terms[0]:\n",
    "    print(prep.spacy_lemmatizer(text = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key token tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"find out about how #donald trump lied at https://t.co/asdfk!lasd08\", 'this is second test sentance trump', \n",
    "        'did you watch the trump impeachment hearings today?']\n",
    "tag_list = ['D', \"R\", \"D\"]\n",
    "\n",
    "def tag_tokens(text_list, token, tag_list):\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub(token, token + \"_\" + tag_list[i], text_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find out about how #donald trump_D lied at https://t.co/asdfk!lasd08',\n",
       " 'this is second test sentance trump_R',\n",
       " 'did you watch the trump_D impeachment hearings today?']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tokens(text, 'trump', tag_list)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_tweets = pd.read_csv('Data/aggregated_tweets.csv')\n",
    "text = aggregated_tweets['text']\n",
    "text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'At 123145 what point did due process become \"cosmetic\" in this country? I don\\'t remember learning that in law school. ðŸ¤” https://t.co/ew1hbvbWBj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At what point did due process become \"cosmetic\" in this country? I don\\'t remember learning that in law school.  https://t.co/ew1hbvbWBj'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demoji.replace(test, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find out about how @realdonald trump lied about obama care at \n"
     ]
    }
   ],
   "source": [
    "test_tokens = ['trump', 'token']\n",
    "text = \"find out about how @realdonaldtrump lied about obamacare at https://t.co/asdfk!lasd08\"\n",
    "tester = 1\n",
    "def twitter_preprocess(text):\n",
    "    \"\"\"\n",
    "    This functions does some preliminary cleaning for twitter text. it will:\n",
    "    1. Remove all pound symbols from text\n",
    "    2. Isolate key words located within hashtags so they can be treated as individual tokens\n",
    "    3. Remove websites from the text\n",
    "    \"\"\"\n",
    "    # remove pound signs\n",
    "    text = re.sub('#', '', text)\n",
    "    # isolate key words located in hashtags\n",
    "    if tester is not None:\n",
    "        for token in key_tokens:\n",
    "            text = re.sub(token, ' ' + token + ' ', text)\n",
    "            text = re.sub('\\s+', ' ', text)\n",
    "    # remove websites\n",
    "    text = re.sub('https:\\S*', '', text)\n",
    "    print(text)\n",
    "\n",
    "twitter_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spacy.load('en', disable = ['tagger', 'parser', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[point,\n",
       " process,\n",
       " cosmetic,\n",
       " country,\n",
       " remember,\n",
       " learning,\n",
       " law,\n",
       " school,\n",
       " ðŸ¤”,\n",
       " https://t.co/ew1hbvbWBj]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strip = tokenizer(test)\n",
    "\n",
    "test_strip = [token for token in test_strip if not token.is_digit | token.is_punct | token.is_stop]\n",
    "test_strip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "file = open('Meta Data/key_tokens.pkl', 'rb')\n",
    "key_tokens = pickle.load(file)\n",
    "\n",
    "file = open('Meta Data/synonym_dictionary.pkl', 'rb')\n",
    "synonyms = pickle.load(file)\n",
    "\n",
    "file = open('Meta Data/stopwords.pkl', 'rb')\n",
    "stopwords = pickle.load(file)\n",
    "\n",
    "meta_data = pd.read_csv('Meta Data/meta_data.csv')\n",
    "\n",
    "tweet_df = pd.read_csv('Data/aggregated_tweets.csv')\n",
    "\n",
    "\n",
    "# merge data with meta data\n",
    "tweet_df = pd.merge(tweet_df, meta_data, how = 'inner', on = 'user_id')\n",
    "\n",
    "tweets = tweet_df['text']\n",
    "labels = tweet_df['party']\n",
    "\n",
    "# initialize parser\n",
    "prep = PrepDocs(stopwords = stopwords, key_tokens = key_tokens, key_synonyms = synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.25 s, sys: 31.1 ms, total: 4.28 s\n",
      "Wall time: 4.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['not',\n",
       "  'long',\n",
       "  'vote',\n",
       "  'impeach_r',\n",
       "  'inquiry',\n",
       "  'open',\n",
       "  'transparent',\n",
       "  'today',\n",
       "  'h',\n",
       "  're',\n",
       "  'learn',\n",
       "  'numerous',\n",
       "  'closed',\n",
       "  'deposition',\n",
       "  'take',\n",
       "  'place',\n",
       "  'week',\n",
       "  's',\n",
       "  'surprising',\n",
       "  'stoptheschiffshow'],\n",
       " ['look',\n",
       "  'forward',\n",
       "  'show',\n",
       "  'repmarkgreen',\n",
       "  'fl',\n",
       "  'week',\n",
       "  'amp',\n",
       "  'introduce',\n",
       "  'outstanding',\n",
       "  'veteran',\n",
       "  'community',\n",
       "  'florida'],\n",
       " ['yes',\n",
       "  'vote',\n",
       "  'resolution',\n",
       "  'give',\n",
       "  'stamp',\n",
       "  'approval',\n",
       "  'process',\n",
       "  'damage',\n",
       "  'repair',\n",
       "  'watch',\n",
       "  'floor',\n",
       "  'speech',\n",
       "  'morning',\n",
       "  'florida',\n",
       "  'fl',\n",
       "  'impeach_r',\n",
       "  'inquiry'],\n",
       " ['house',\n",
       "  'vote',\n",
       "  'resolution',\n",
       "  'formalize',\n",
       "  'impeach_r',\n",
       "  'inquiry',\n",
       "  'realdonaldtrump',\n",
       "  'damage',\n",
       "  'clear',\n",
       "  'democrat',\n",
       "  'interested',\n",
       "  'precedent',\n",
       "  'process',\n",
       "  'goal',\n",
       "  'remove',\n",
       "  'potus',\n",
       "  'office',\n",
       "  'period'],\n",
       " ['dc',\n",
       "  'team',\n",
       "  'happy',\n",
       "  'help',\n",
       "  'theuso',\n",
       "  'afternoon',\n",
       "  'total',\n",
       "  'care',\n",
       "  'package',\n",
       "  'assemble',\n",
       "  'deployed',\n",
       "  'service',\n",
       "  'member',\n",
       "  'thank',\n",
       "  'defend',\n",
       "  'freedom',\n",
       "  'uso',\n",
       "  'force',\n",
       "  'armed',\n",
       "  'force',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['thank',\n",
       "  'kelliemeyernew',\n",
       "  'interview',\n",
       "  'today',\n",
       "  'look',\n",
       "  'interview',\n",
       "  'boee',\n",
       "  'max',\n",
       "  'hearing',\n",
       "  'wfla',\n",
       "  'evening',\n",
       "  'florida',\n",
       "  'fl',\n",
       "  'transportgop'],\n",
       " ['step',\n",
       "  'house',\n",
       "  'tampi',\n",
       "  'committee',\n",
       "  'hearing',\n",
       "  'boee',\n",
       "  'max',\n",
       "  'brief',\n",
       "  'moment',\n",
       "  'watch',\n",
       "  'live',\n",
       "  'feed',\n",
       "  'transportgop'],\n",
       " ['s',\n",
       "  'number',\n",
       "  'legislative',\n",
       "  'day',\n",
       "  'leave',\n",
       "  'fully',\n",
       "  'fund',\n",
       "  'military',\n",
       "  'democrat',\n",
       "  'laser',\n",
       "  'focus',\n",
       "  'impeach_r',\n",
       "  'instead',\n",
       "  'priority',\n",
       "  'lie'],\n",
       " ['little', 'late', 'democrats', 'motive', 'reveal', 'validate'],\n",
       " ['be',\n",
       "  'grateful',\n",
       "  'colleague',\n",
       "  'amp',\n",
       "  'work',\n",
       "  'polkschoolsnew',\n",
       "  'assistance',\n",
       "  'need',\n",
       "  'thank',\n",
       "  'repdarrensoto',\n",
       "  'amp',\n",
       "  'repgregsteube',\n",
       "  'outstanding',\n",
       "  'bipartisan',\n",
       "  'effort',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['update',\n",
       "  'step',\n",
       "  'house',\n",
       "  'intelligence',\n",
       "  'comm',\n",
       "  'meeting',\n",
       "  'vote',\n",
       "  'unfortunately',\n",
       "  'chairman',\n",
       "  'schiff',\n",
       "  'immediately',\n",
       "  'stop',\n",
       "  'hearing',\n",
       "  'amp',\n",
       "  'leave',\n",
       "  'witness',\n",
       "  'arrival',\n",
       "  'stoptheschiffshow'],\n",
       " ['lose',\n",
       "  'voice',\n",
       "  'not',\n",
       "  'go',\n",
       "  'stop',\n",
       "  'draw',\n",
       "  'attention',\n",
       "  'important',\n",
       "  'issue',\n",
       "  'impeach_r',\n",
       "  'inquiry',\n",
       "  'short',\n",
       "  'mess',\n",
       "  'process',\n",
       "  'democrat',\n",
       "  'lead',\n",
       "  'unilateral',\n",
       "  'secretive',\n",
       "  'unacceptable',\n",
       "  'stoptheschiffshow'],\n",
       " ['want',\n",
       "  'transparency',\n",
       "  'plain',\n",
       "  'simple',\n",
       "  'wellinformed',\n",
       "  'decision',\n",
       "  'not',\n",
       "  'access',\n",
       "  'info',\n",
       "  'american',\n",
       "  'deserve',\n",
       "  'transparency',\n",
       "  'stoptheschiffshow'],\n",
       " ['republicanstudy',\n",
       "  'work',\n",
       "  'develop',\n",
       "  'personalized',\n",
       "  'plan',\n",
       "  'preexist',\n",
       "  'condition',\n",
       "  'know',\n",
       "  'importance',\n",
       "  'have',\n",
       "  'meaningful',\n",
       "  'healthcare',\n",
       "  'plan',\n",
       "  'not',\n",
       "  'onesizedfitsall',\n",
       "  'healthcareu'],\n",
       " ['ashley',\n",
       "  'hall',\n",
       "  'mother',\n",
       "  'young',\n",
       "  'girl',\n",
       "  'daughter',\n",
       "  'sister',\n",
       "  'dance',\n",
       "  'instructor',\n",
       "  'teacher',\n",
       "  'aid',\n",
       "  'victim',\n",
       "  'domestic',\n",
       "  'violence',\n",
       "  'domesticviolenceawarenessmonth',\n",
       "  'let',\n",
       "  'ashley',\n",
       "  'story',\n",
       "  'motivator',\n",
       "  'help',\n",
       "  'help',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['thank',\n",
       "  'orlandosentinel',\n",
       "  'publish',\n",
       "  'worry',\n",
       "  'unexpected',\n",
       "  'medical',\n",
       "  'bill',\n",
       "  'especially',\n",
       "  'insure',\n",
       "  'glad',\n",
       "  'join',\n",
       "  'senrickscott',\n",
       "  'continue',\n",
       "  'address',\n",
       "  'increasingly',\n",
       "  'common',\n",
       "  'issue',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['accountability', 'key', 'lie', 'american', 'people', 'condemn'],\n",
       " ['pray',\n",
       "  'impact',\n",
       "  'storm',\n",
       "  'hit',\n",
       "  'polkcounty',\n",
       "  'have',\n",
       "  'rebuild',\n",
       "  'strong',\n",
       "  'well',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['impeach_r',\n",
       "  'process',\n",
       "  'topic',\n",
       "  'surround',\n",
       "  'kurdish',\n",
       "  'ally',\n",
       "  'fight',\n",
       "  'issue',\n",
       "  'veteran',\n",
       "  'fl',\n",
       "  'hectic',\n",
       "  'week',\n",
       "  'catch',\n",
       "  'happen',\n",
       "  'washington',\n",
       "  'weekly',\n",
       "  'recap',\n",
       "  'video',\n",
       "  'florida'],\n",
       " ['thank',\n",
       "  'sorenson',\n",
       "  'family',\n",
       "  'lakeland',\n",
       "  'visit',\n",
       "  'today',\n",
       "  'nice',\n",
       "  'connect',\n",
       "  'folk',\n",
       "  'home',\n",
       "  'washington',\n",
       "  'family',\n",
       "  'interested',\n",
       "  'tour',\n",
       "  'capitol',\n",
       "  'reach',\n",
       "  'dc',\n",
       "  'office',\n",
       "  'arrange',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['be',\n",
       "  'proud',\n",
       "  'team',\n",
       "  'passion',\n",
       "  'serve',\n",
       "  'fl',\n",
       "  'community',\n",
       "  'dc',\n",
       "  'community',\n",
       "  'huge',\n",
       "  'thank',\n",
       "  'rmhcdc',\n",
       "  'allow',\n",
       "  'team',\n",
       "  'involve'],\n",
       " ['chance',\n",
       "  'spend',\n",
       "  'time',\n",
       "  'friend',\n",
       "  'gil',\n",
       "  'neuman',\n",
       "  'morning',\n",
       "  'discuss',\n",
       "  'dysfunction',\n",
       "  'washington',\n",
       "  'dc',\n",
       "  'way',\n",
       "  'difference',\n",
       "  'behalf',\n",
       "  'constituent',\n",
       "  'amp',\n",
       "  'better',\n",
       "  'understand',\n",
       "  'geopolitical',\n",
       "  'dynamic',\n",
       "  'middle',\n",
       "  'east',\n",
       "  'florida'],\n",
       " ['sadden',\n",
       "  'loss',\n",
       "  'colleague',\n",
       "  'repcumming',\n",
       "  'be',\n",
       "  'grateful',\n",
       "  'opportunity',\n",
       "  'serve',\n",
       "  'amp',\n",
       "  'contribution',\n",
       "  'congress',\n",
       "  'thought',\n",
       "  'prayer',\n",
       "  'family',\n",
       "  'amp',\n",
       "  'community',\n",
       "  'time'],\n",
       " ['night',\n",
       "  'house',\n",
       "  'unanimously',\n",
       "  'pass',\n",
       "  'hr',\n",
       "  'reimburse',\n",
       "  'community',\n",
       "  'org',\n",
       "  'serve',\n",
       "  'homeless',\n",
       "  'veteran',\n",
       "  'cost',\n",
       "  'associate',\n",
       "  'w',\n",
       "  'child',\n",
       "  'vet',\n",
       "  'endure',\n",
       "  'tough',\n",
       "  'condition',\n",
       "  'overseas',\n",
       "  'face',\n",
       "  'issue',\n",
       "  'home',\n",
       "  'florida',\n",
       "  'fl'],\n",
       " ['republican',\n",
       "  'member',\n",
       "  'congress',\n",
       "  'grant',\n",
       "  'access',\n",
       "  'testimony',\n",
       "  'evidence',\n",
       "  'lead',\n",
       "  'impeach_r',\n",
       "  'realdonaldtrump',\n",
       "  'housedemocrat',\n",
       "  'hide'],\n",
       " ['mr',\n",
       "  'schiff',\n",
       "  'prior',\n",
       "  'knowledge',\n",
       "  'whistle',\n",
       "  'blower',\n",
       "  'testimony',\n",
       "  'give',\n",
       "  'fabricated',\n",
       "  'version',\n",
       "  'transcript',\n",
       "  'realdonaldtrump',\n",
       "  'ukrainian',\n",
       "  'president',\n",
       "  'spread',\n",
       "  'false',\n",
       "  'narrative',\n",
       "  'collusion',\n",
       "  'schiff',\n",
       "  'hold',\n",
       "  'accountable'],\n",
       " ['point',\n",
       "  'process',\n",
       "  'cosmetic',\n",
       "  'country',\n",
       "  'not',\n",
       "  'remember',\n",
       "  'learn',\n",
       "  'law',\n",
       "  'school'],\n",
       " ['be',\n",
       "  'reflect',\n",
       "  'experience',\n",
       "  'week',\n",
       "  'visit',\n",
       "  'good',\n",
       "  'smallbusinesse',\n",
       "  'lakecounty',\n",
       "  'offer',\n",
       "  'different',\n",
       "  'share',\n",
       "  'true',\n",
       "  'entrepreneurial',\n",
       "  'spirit',\n",
       "  'honor',\n",
       "  'spend',\n",
       "  'time',\n",
       "  'florida',\n",
       "  'fl'],\n",
       " ['wish',\n",
       "  'usnavy',\n",
       "  'happy',\n",
       "  'th',\n",
       "  'birthday',\n",
       "  'continental',\n",
       "  'congress',\n",
       "  'establish',\n",
       "  'naval',\n",
       "  'force',\n",
       "  'october',\n",
       "  'navy',\n",
       "  'pivotal',\n",
       "  'military',\n",
       "  'thank',\n",
       "  'serve',\n",
       "  'country',\n",
       "  'happybirthdaynavy'],\n",
       " ['speaker',\n",
       "  'follow',\n",
       "  'precedent',\n",
       "  'impeach_r',\n",
       "  'inquiry',\n",
       "  'realdonaldtrump',\n",
       "  'democrat',\n",
       "  'not',\n",
       "  'want',\n",
       "  'force',\n",
       "  'record',\n",
       "  'vote',\n",
       "  'correct',\n",
       "  'unfair',\n",
       "  'unilateral',\n",
       "  'process'],\n",
       " ['exactly',\n",
       "  'gopleader',\n",
       "  'say',\n",
       "  'best',\n",
       "  'real',\n",
       "  'issue',\n",
       "  'plausible',\n",
       "  'solution',\n",
       "  'washington',\n",
       "  'american',\n",
       "  'want',\n",
       "  'crumble',\n",
       "  'infrastructure',\n",
       "  'restore',\n",
       "  'deserve',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['wow',\n",
       "  'unemploymentrate',\n",
       "  'hit',\n",
       "  'year',\n",
       "  'low',\n",
       "  'w',\n",
       "  'mil',\n",
       "  'job',\n",
       "  'create',\n",
       "  'congrat',\n",
       "  'realdonaldtrump',\n",
       "  'congress',\n",
       "  'american',\n",
       "  'workforce',\n",
       "  'incredible',\n",
       "  'accomplishment'],\n",
       " ['chance',\n",
       "  'great',\n",
       "  'read',\n",
       "  'pension',\n",
       "  'pedophile',\n",
       "  'act',\n",
       "  'sponsor',\n",
       "  'thank',\n",
       "  'theledger',\n",
       "  'editorial',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['reach',\n",
       "  'final',\n",
       "  'day',\n",
       "  'hispanicheritagemonth',\n",
       "  'want',\n",
       "  'time',\n",
       "  'thank',\n",
       "  'hispanic',\n",
       "  'latinx',\n",
       "  'member',\n",
       "  'fl',\n",
       "  'nearly',\n",
       "  'district',\n",
       "  'hispanic',\n",
       "  'latinx',\n",
       "  'hispanic',\n",
       "  'trailblazer',\n",
       "  'yesterday',\n",
       "  'tomorrow',\n",
       "  'thank'],\n",
       " ['student',\n",
       "  'interested',\n",
       "  'attend',\n",
       "  'service',\n",
       "  'academy',\n",
       "  'request',\n",
       "  'military',\n",
       "  'academy',\n",
       "  'nomination',\n",
       "  'submit',\n",
       "  'complete',\n",
       "  'application',\n",
       "  'packet',\n",
       "  'friday',\n",
       "  'october',\n",
       "  'yes',\n",
       "  'friday',\n",
       "  'learn',\n",
       "  'fl',\n",
       "  'florida',\n",
       "  'military'],\n",
       " ['honestly',\n",
       "  'favorite',\n",
       "  'story',\n",
       "  'day',\n",
       "  'outpouring',\n",
       "  'love',\n",
       "  'nation',\n",
       "  'brave',\n",
       "  'excellent',\n",
       "  'reminder',\n",
       "  'make',\n",
       "  'country',\n",
       "  'great',\n",
       "  'heart',\n",
       "  'thank',\n",
       "  'able',\n",
       "  'trip',\n",
       "  'sarasota',\n",
       "  'today',\n",
       "  'florida'],\n",
       " ['oct',\n",
       "  'breastcancerawarenessmonth',\n",
       "  's',\n",
       "  'well',\n",
       "  'way',\n",
       "  'kick',\n",
       "  'month',\n",
       "  'meet',\n",
       "  'folk',\n",
       "  'moffittnew',\n",
       "  'afternoon',\n",
       "  'woman',\n",
       "  'develop',\n",
       "  'breastcancer',\n",
       "  'man',\n",
       "  'diagnose',\n",
       "  'year',\n",
       "  'join',\n",
       "  'fight',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['wish',\n",
       "  'happy',\n",
       "  'roshhashanah',\n",
       "  'celebrate',\n",
       "  'jewish',\n",
       "  'new',\n",
       "  'year',\n",
       "  'reflect',\n",
       "  'trip',\n",
       "  'israel',\n",
       "  'month',\n",
       "  'learn',\n",
       "  'unforgettable',\n",
       "  'trip',\n",
       "  'forever',\n",
       "  'grateful',\n",
       "  'experience',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['pleasure',\n",
       "  'get',\n",
       "  'work',\n",
       "  'fl',\n",
       "  'fantastic',\n",
       "  'crew',\n",
       "  'leslie',\n",
       "  'control',\n",
       "  'found',\n",
       "  'serve',\n",
       "  'tampa',\n",
       "  'year',\n",
       "  'thank',\n",
       "  'leslie',\n",
       "  'control',\n",
       "  'let',\n",
       "  'tour',\n",
       "  'facility',\n",
       "  'speak',\n",
       "  'team',\n",
       "  'florida',\n",
       "  'circorint'],\n",
       " ['cardiovascular',\n",
       "  'disease',\n",
       "  'world',\n",
       "  'lead',\n",
       "  'cause',\n",
       "  'death',\n",
       "  'heart',\n",
       "  'condition',\n",
       "  'subject',\n",
       "  'hit',\n",
       "  'particularly',\n",
       "  'close',\n",
       "  'home',\n",
       "  'join',\n",
       "  'observe',\n",
       "  'worldheartday',\n",
       "  'watch',\n",
       "  'speech',\n",
       "  'house',\n",
       "  'floor'],\n",
       " ['time',\n",
       "  'work',\n",
       "  'secure',\n",
       "  'border',\n",
       "  'watch',\n",
       "  'speech',\n",
       "  'fl',\n",
       "  'florida',\n",
       "  'immigration',\n",
       "  'secureourborder'],\n",
       " ['ill',\n",
       "  'kick',\n",
       "  'teletownhall',\n",
       "  'minute',\n",
       "  'stay',\n",
       "  'tune',\n",
       "  'update',\n",
       "  'not',\n",
       "  'able',\n",
       "  'join',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['meet',\n",
       "  'group',\n",
       "  'high',\n",
       "  'school',\n",
       "  'student',\n",
       "  'home',\n",
       "  'travel',\n",
       "  'dc',\n",
       "  'rfoundation',\n",
       "  'encourage',\n",
       "  'young',\n",
       "  'people',\n",
       "  'engage',\n",
       "  'government',\n",
       "  'yesterday',\n",
       "  'receive',\n",
       "  'note',\n",
       "  'kind',\n",
       "  'word',\n",
       "  'encouragement',\n",
       "  'mean',\n",
       "  'lot',\n",
       "  'thank',\n",
       "  'visit',\n",
       "  'fl'],\n",
       " ['today',\n",
       "  'democrat',\n",
       "  'clear',\n",
       "  'intention',\n",
       "  'follow',\n",
       "  'longstanding',\n",
       "  'house',\n",
       "  'practice',\n",
       "  'impeach_r',\n",
       "  'inquiry'],\n",
       " ['speak',\n",
       "  'house',\n",
       "  'floor',\n",
       "  'transcript',\n",
       "  'president',\n",
       "  'realdonaldtrump',\n",
       "  'conversation',\n",
       "  'ukrainian',\n",
       "  'president',\n",
       "  'simply',\n",
       "  'topic',\n",
       "  'roadblock',\n",
       "  'keep',\n",
       "  'pass',\n",
       "  'meaningful',\n",
       "  'legislation'],\n",
       " ['september',\n",
       "  'national',\n",
       "  'suicide',\n",
       "  'prevention',\n",
       "  'month',\n",
       "  'time',\n",
       "  'betheto',\n",
       "  'act',\n",
       "  'ally',\n",
       "  'know',\n",
       "  'warning',\n",
       "  'sign',\n",
       "  'need',\n",
       "  'help',\n",
       "  'know',\n",
       "  'national',\n",
       "  'suicide',\n",
       "  'prevention',\n",
       "  'hotline'],\n",
       " ['state', 'heart', 'florida', 'fl'],\n",
       " ['powmia',\n",
       "  'recognition',\n",
       "  'day',\n",
       "  'let',\n",
       "  'moment',\n",
       "  'eternal',\n",
       "  'gratitude',\n",
       "  'thank',\n",
       "  'give',\n",
       "  'ultimate',\n",
       "  'sacrifice',\n",
       "  'powmia',\n",
       "  'veteransaffair'],\n",
       " ['fun',\n",
       "  'get',\n",
       "  'silly',\n",
       "  'smiley',\n",
       "  'family',\n",
       "  'today',\n",
       "  'interested',\n",
       "  'visit',\n",
       "  'dc',\n",
       "  'office',\n",
       "  'go',\n",
       "  'tour',\n",
       "  'capitol',\n",
       "  'sign',\n",
       "  'website'],\n",
       " ['great',\n",
       "  'able',\n",
       "  'sit',\n",
       "  'tampas',\n",
       "  'fine',\n",
       "  'philanthropist',\n",
       "  'afternoon',\n",
       "  'metroministrie',\n",
       "  'thank',\n",
       "  'help',\n",
       "  'community',\n",
       "  'congrat',\n",
       "  'asc',\n",
       "  'innovation',\n",
       "  'amp',\n",
       "  'leadership',\n",
       "  'award'],\n",
       " ['want',\n",
       "  'moment',\n",
       "  'shine',\n",
       "  'light',\n",
       "  'grow',\n",
       "  'issue',\n",
       "  'impact',\n",
       "  'nation',\n",
       "  'vet',\n",
       "  'honor',\n",
       "  'suicidepreventionmonth',\n",
       "  'join',\n",
       "  'share',\n",
       "  'resource',\n",
       "  'florida',\n",
       "  'veteran',\n",
       "  'support',\n",
       "  'line',\n",
       "  'myflvet',\n",
       "  'veteran',\n",
       "  'crisis',\n",
       "  'line',\n",
       "  'press',\n",
       "  'bethere'],\n",
       " ['absolute',\n",
       "  'pleasure',\n",
       "  'meeting',\n",
       "  'karen',\n",
       "  'kerr',\n",
       "  'president',\n",
       "  'south',\n",
       "  'florida',\n",
       "  'baptist',\n",
       "  'hospital',\n",
       "  'plant',\n",
       "  'city',\n",
       "  'discuss',\n",
       "  'healthcare',\n",
       "  'issue',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['yrs',\n",
       "  'ago',\n",
       "  'found',\n",
       "  'father',\n",
       "  'lay',\n",
       "  'cornerstone',\n",
       "  'govt',\n",
       "  'signing',\n",
       "  'constitution',\n",
       "  'united',\n",
       "  'state',\n",
       "  'begin',\n",
       "  'simple',\n",
       "  'thought',\n",
       "  'amp',\n",
       "  'ambitious',\n",
       "  'dream',\n",
       "  'time',\n",
       "  'turn',\n",
       "  'development',\n",
       "  'great',\n",
       "  'nation',\n",
       "  'earth',\n",
       "  'happy',\n",
       "  'constitutionday'],\n",
       " ['honor',\n",
       "  'participate',\n",
       "  'combat',\n",
       "  'veteran',\n",
       "  'homelessness',\n",
       "  'tampa',\n",
       "  'bay',\n",
       "  'area',\n",
       "  'hearing',\n",
       "  'today',\n",
       "  'w',\n",
       "  'colleague',\n",
       "  'repmikelevin',\n",
       "  'amp',\n",
       "  'repgusbilirakis',\n",
       "  'friend',\n",
       "  'dannyburgessfl',\n",
       "  'watch',\n",
       "  'hearing',\n",
       "  'veteransaffair',\n",
       "  'fl',\n",
       "  'fl'],\n",
       " ['week',\n",
       "  'ope',\n",
       "  'small',\n",
       "  'business',\n",
       "  'tour',\n",
       "  'publish',\n",
       "  'theledger',\n",
       "  'have',\n",
       "  'enjoy',\n",
       "  'time',\n",
       "  'tour',\n",
       "  'facility',\n",
       "  'amp',\n",
       "  'speak',\n",
       "  'small',\n",
       "  'business',\n",
       "  'owner',\n",
       "  'issue',\n",
       "  'currently',\n",
       "  'face',\n",
       "  'small',\n",
       "  'business',\n",
       "  'tour',\n",
       "  'resume',\n",
       "  'oct',\n",
       "  'fl'],\n",
       " ['happy',\n",
       "  'friday',\n",
       "  'week',\n",
       "  'august',\n",
       "  'recess',\n",
       "  'busy',\n",
       "  'productive',\n",
       "  'here',\n",
       "  'quick',\n",
       "  'rundown',\n",
       "  'happen',\n",
       "  'week',\n",
       "  'fl',\n",
       "  'fl',\n",
       "  'detail',\n",
       "  'feel',\n",
       "  'free',\n",
       "  'signup',\n",
       "  'weekly',\n",
       "  'newsletter'],\n",
       " ['yesterday',\n",
       "  'house',\n",
       "  'vote',\n",
       "  'hr',\n",
       "  'oil',\n",
       "  'drilling',\n",
       "  'moratorium',\n",
       "  'florida',\n",
       "  'coast',\n",
       "  'permanent',\n",
       "  'vote',\n",
       "  'yes',\n",
       "  'bill',\n",
       "  'protect',\n",
       "  'fls',\n",
       "  'beach',\n",
       "  'amp',\n",
       "  'economy',\n",
       "  'protectourcoast'],\n",
       " ['surprise',\n",
       "  'medical',\n",
       "  'billing',\n",
       "  'known',\n",
       "  'trap',\n",
       "  'healthcare',\n",
       "  'system',\n",
       "  'decade',\n",
       "  'honor',\n",
       "  'join',\n",
       "  'senrickscott',\n",
       "  'continue',\n",
       "  'effort',\n",
       "  'address',\n",
       "  'increasingly',\n",
       "  'common',\n",
       "  'issue',\n",
       "  'truly',\n",
       "  'hope',\n",
       "  'american',\n",
       "  'able',\n",
       "  'floridian',\n",
       "  'fl'],\n",
       " ['september',\n",
       "  'th',\n",
       "  'scar',\n",
       "  'heart',\n",
       "  'american',\n",
       "  'forever',\n",
       "  'day',\n",
       "  'lose',\n",
       "  'symbol',\n",
       "  'sorrow',\n",
       "  'growth',\n",
       "  'september',\n",
       "  'neverforget'],\n",
       " ['time',\n",
       "  'clear',\n",
       "  'terror',\n",
       "  'officially',\n",
       "  'strike',\n",
       "  'north',\n",
       "  'tower',\n",
       "  'collapse',\n",
       "  'trap',\n",
       "  'hundred',\n",
       "  'civilian',\n",
       "  'responder',\n",
       "  'inside',\n",
       "  'day',\n",
       "  'remember',\n",
       "  'date',\n",
       "  'represent'],\n",
       " ['american',\n",
       "  'hero',\n",
       "  'take',\n",
       "  'stand',\n",
       "  'flight',\n",
       "  'go',\n",
       "  'pennsylvania',\n",
       "  'field',\n",
       "  'take',\n",
       "  'dozen',\n",
       "  'life',\n",
       "  'hit',\n",
       "  'intended',\n",
       "  'target',\n",
       "  'nation',\n",
       "  'capital'],\n",
       " ['disaster',\n",
       "  'new',\n",
       "  'york',\n",
       "  'begin',\n",
       "  'calm',\n",
       "  'thing',\n",
       "  'quickly',\n",
       "  'go',\n",
       "  'bad',\n",
       "  'bad',\n",
       "  'south',\n",
       "  'tower',\n",
       "  'collapse'],\n",
       " ['new',\n",
       "  'york',\n",
       "  'target',\n",
       "  'hijacked',\n",
       "  'plane',\n",
       "  'strike',\n",
       "  'pentagon',\n",
       "  'effort',\n",
       "  'bring',\n",
       "  'nation',\n",
       "  'knee'],\n",
       " ['minute',\n",
       "  'plane',\n",
       "  'strike',\n",
       "  'world',\n",
       "  'trade',\n",
       "  'center',\n",
       "  'nation',\n",
       "  'scramble',\n",
       "  'figure',\n",
       "  'tragic',\n",
       "  'accident',\n",
       "  'happen',\n",
       "  'time',\n",
       "  'reality',\n",
       "  'begin',\n",
       "  'sit',\n",
       "  'south',\n",
       "  'tower',\n",
       "  'strike'],\n",
       " ['work',\n",
       "  'morning',\n",
       "  'routine',\n",
       "  'think',\n",
       "  'different',\n",
       "  'thing',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'time',\n",
       "  'north',\n",
       "  'tower',\n",
       "  'strike'],\n",
       " ['veteran',\n",
       "  'sacrifice',\n",
       "  'time',\n",
       "  'bethere',\n",
       "  'veteran',\n",
       "  'active',\n",
       "  'duty',\n",
       "  'service',\n",
       "  'member',\n",
       "  'crisis',\n",
       "  'read',\n",
       "  'editorial',\n",
       "  'learn',\n",
       "  'help',\n",
       "  'worldsuicidepreventionday',\n",
       "  'veteran',\n",
       "  'fl'],\n",
       " ['prepare',\n",
       "  'speak',\n",
       "  'support',\n",
       "  'bornalive',\n",
       "  'abortion',\n",
       "  'survivor',\n",
       "  'protection',\n",
       "  'act',\n",
       "  'tune',\n",
       "  'endinfantcide'],\n",
       " ['build',\n",
       "  'skyscraper',\n",
       "  'year',\n",
       "  'long',\n",
       "  'build',\n",
       "  'va',\n",
       "  'outpatient',\n",
       "  'clinic',\n",
       "  'lakeland',\n",
       "  'hope',\n",
       "  'house',\n",
       "  'veteran',\n",
       "  'affair',\n",
       "  'committee',\n",
       "  'work',\n",
       "  'expedite',\n",
       "  'process',\n",
       "  'fl',\n",
       "  'veteran'],\n",
       " ['be',\n",
       "  'speak',\n",
       "  'house',\n",
       "  'committee',\n",
       "  'veteran',\n",
       "  'affair',\n",
       "  'member',\n",
       "  'day',\n",
       "  'va',\n",
       "  'clinic',\n",
       "  'lakeland',\n",
       "  'fl'],\n",
       " ['hold',\n",
       "  'hearing',\n",
       "  'bornalive',\n",
       "  'abortion',\n",
       "  'survivor',\n",
       "  'protection',\n",
       "  'act',\n",
       "  'today',\n",
       "  'expert',\n",
       "  'witness',\n",
       "  'abortion',\n",
       "  'procedure',\n",
       "  'amp',\n",
       "  'statistic',\n",
       "  'watch',\n",
       "  'live',\n",
       "  'stream',\n",
       "  'hearing',\n",
       "  'pm',\n",
       "  'eastern',\n",
       "  'endinfantcide'],\n",
       " ['enter',\n",
       "  'hiroshima',\n",
       "  'follow',\n",
       "  'atomic',\n",
       "  'bomb',\n",
       "  'deploy',\n",
       "  'vietnam',\n",
       "  'colonel',\n",
       "  'andy',\n",
       "  'koehl',\n",
       "  'embody',\n",
       "  'true',\n",
       "  'meaning',\n",
       "  'heroism',\n",
       "  'truly',\n",
       "  'privilege',\n",
       "  'honor',\n",
       "  'house',\n",
       "  'floor',\n",
       "  'night',\n",
       "  'veteranofthemonth',\n",
       "  'fl',\n",
       "  'florida'],\n",
       " ['not',\n",
       "  'forget',\n",
       "  'deadline',\n",
       "  'register',\n",
       "  'congressional',\n",
       "  'app',\n",
       "  'challenge',\n",
       "  'september',\n",
       "  'th',\n",
       "  'sunday'],\n",
       " ['journey',\n",
       "  'israel',\n",
       "  'trip',\n",
       "  'lifetime',\n",
       "  'able',\n",
       "  'walk',\n",
       "  'biblical',\n",
       "  'figure',\n",
       "  'like',\n",
       "  'david',\n",
       "  'amp',\n",
       "  'goliath',\n",
       "  'walk',\n",
       "  'truly',\n",
       "  'humbling',\n",
       "  'experience',\n",
       "  'read',\n",
       "  'experience',\n",
       "  'takeaway',\n",
       "  'trip'],\n",
       " ['multiple',\n",
       "  'conf',\n",
       "  'call',\n",
       "  'wfema',\n",
       "  'fl',\n",
       "  'div',\n",
       "  'emergency',\n",
       "  'mgmt',\n",
       "  'confirm',\n",
       "  'org',\n",
       "  'remain',\n",
       "  'engaged',\n",
       "  'focus',\n",
       "  'open',\n",
       "  'shelter',\n",
       "  'contingency',\n",
       "  'planning',\n",
       "  'damage',\n",
       "  'assessment',\n",
       "  'floridian',\n",
       "  'neighbor',\n",
       "  'north',\n",
       "  'grateful',\n",
       "  'strong',\n",
       "  'support'],\n",
       " ['dorian',\n",
       "  'delay',\n",
       "  'arrival',\n",
       "  'give',\n",
       "  'time',\n",
       "  'prepare',\n",
       "  'coast',\n",
       "  'inland',\n",
       "  'imperative',\n",
       "  'precaution',\n",
       "  'hurricanedorian',\n",
       "  'florida',\n",
       "  'fl'],\n",
       " ['thank',\n",
       "  'sherry',\n",
       "  'wheelock',\n",
       "  'soflinfo',\n",
       "  'team',\n",
       "  'allow',\n",
       "  'tour',\n",
       "  'facility',\n",
       "  'today',\n",
       "  'fl',\n",
       "  'specialolympic'],\n",
       " ['happy',\n",
       "  'international',\n",
       "  'dog',\n",
       "  'day',\n",
       "  'charlie',\n",
       "  'cut',\n",
       "  'dachshund',\n",
       "  'world',\n",
       "  'internationaldogday',\n",
       "  'mansbestfriend'],\n",
       " ['thank',\n",
       "  'have',\n",
       "  'pleasure',\n",
       "  'meeting',\n",
       "  'amp',\n",
       "  'tour',\n",
       "  'wonderful',\n",
       "  'campus'],\n",
       " ['morning',\n",
       "  'pleasure',\n",
       "  'tour',\n",
       "  'harrellsllc',\n",
       "  'production',\n",
       "  'facility',\n",
       "  'successful',\n",
       "  'small',\n",
       "  'business',\n",
       "  'base',\n",
       "  'right',\n",
       "  'fl',\n",
       "  'currently',\n",
       "  'reach',\n",
       "  'state',\n",
       "  'amp',\n",
       "  'continue',\n",
       "  'grow',\n",
       "  'thank',\n",
       "  'scott',\n",
       "  'sam',\n",
       "  'show',\n",
       "  'smallbusiness',\n",
       "  'florida'],\n",
       " ['ahla',\n",
       "  'human',\n",
       "  'trafficking',\n",
       "  'country',\n",
       "  'important',\n",
       "  'issue',\n",
       "  'awesome',\n",
       "  'idea',\n",
       "  'hope',\n",
       "  'initiative',\n",
       "  'like',\n",
       "  'near',\n",
       "  'future',\n",
       "  'humantrafficke',\n",
       "  'noroom',\n",
       "  'fl'],\n",
       " ['welcome',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'hillsborough',\n",
       "  'co',\n",
       "  'lake',\n",
       "  'co',\n",
       "  'amp',\n",
       "  'polk',\n",
       "  'co',\n",
       "  'hope',\n",
       "  'wonderful',\n",
       "  'amp',\n",
       "  'productive',\n",
       "  'school',\n",
       "  'year',\n",
       "  'backtoschool',\n",
       "  'fl'],\n",
       " ['thank', 'm', 'amp', 'b', 'product', 'chat', 'spanosmallbiztour', 'fl'],\n",
       " ['shout',\n",
       "  'bill',\n",
       "  'prescription',\n",
       "  'center',\n",
       "  'let',\n",
       "  'stop',\n",
       "  'chat',\n",
       "  'spanosmallbiztour',\n",
       "  'fun',\n",
       "  'fact',\n",
       "  'bill',\n",
       "  'serve',\n",
       "  'brandon',\n",
       "  'area',\n",
       "  's',\n",
       "  'fl'],\n",
       " ['special',\n",
       "  'thank',\n",
       "  'manny',\n",
       "  'john',\n",
       "  'noah',\n",
       "  'myelectrictoday',\n",
       "  'chat',\n",
       "  'spanosmallbiztour',\n",
       "  'fl'],\n",
       " ['stop',\n",
       "  'pronesisgrp',\n",
       "  'hello',\n",
       "  'jeff',\n",
       "  'sheffer',\n",
       "  'gang',\n",
       "  'spanosmallbiztour',\n",
       "  'stay',\n",
       "  'tune',\n",
       "  'coverage',\n",
       "  'fl'],\n",
       " ['good',\n",
       "  'morning',\n",
       "  'pleasure',\n",
       "  'stop',\n",
       "  'paatinsurance',\n",
       "  'office',\n",
       "  'plant',\n",
       "  'city',\n",
       "  'spanosmallbiztour',\n",
       "  'check',\n",
       "  'video',\n",
       "  'courtney',\n",
       "  'amp',\n",
       "  'stay',\n",
       "  'tune',\n",
       "  'footage',\n",
       "  'small',\n",
       "  'business',\n",
       "  'tour',\n",
       "  'fl'],\n",
       " ['literally',\n",
       "  'hit',\n",
       "  'close',\n",
       "  'home',\n",
       "  'gas',\n",
       "  'station',\n",
       "  'victim',\n",
       "  'find',\n",
       "  'mile',\n",
       "  'home',\n",
       "  'stay',\n",
       "  'alert',\n",
       "  'amp',\n",
       "  'safe',\n",
       "  'fl'],\n",
       " ['shout',\n",
       "  'minuteman',\n",
       "  'press',\n",
       "  'plant',\n",
       "  'city',\n",
       "  'allow',\n",
       "  'stop',\n",
       "  'spanosmallbiztour',\n",
       "  'video',\n",
       "  'come',\n",
       "  'soon',\n",
       "  'fl',\n",
       "  'smallbusiness'],\n",
       " ['stay',\n",
       "  'tune',\n",
       "  'video',\n",
       "  'tour',\n",
       "  'small',\n",
       "  'business',\n",
       "  'district',\n",
       "  'fl',\n",
       "  'smallbusiness'],\n",
       " ['afternoon',\n",
       "  'pleasure',\n",
       "  'visit',\n",
       "  'undercrofthq',\n",
       "  'ybor',\n",
       "  'city',\n",
       "  'cowork',\n",
       "  'space',\n",
       "  'incubator',\n",
       "  'cyber',\n",
       "  'security',\n",
       "  'startup',\n",
       "  'training',\n",
       "  'center',\n",
       "  'student',\n",
       "  'learn',\n",
       "  'cyber',\n",
       "  'security',\n",
       "  'found',\n",
       "  'run',\n",
       "  'veteran',\n",
       "  'flapol',\n",
       "  'fl'],\n",
       " ['hard',\n",
       "  'find',\n",
       "  'right',\n",
       "  'word',\n",
       "  'adequately',\n",
       "  'convey',\n",
       "  'deeply',\n",
       "  'sadden',\n",
       "  'tragic',\n",
       "  'event',\n",
       "  'take',\n",
       "  'place',\n",
       "  'dayton',\n",
       "  'amp',\n",
       "  'el',\n",
       "  'paso',\n",
       "  'act',\n",
       "  'hatred',\n",
       "  'violence',\n",
       "  'senseless',\n",
       "  'wrong'],\n",
       " ['s',\n",
       "  'well',\n",
       "  'way',\n",
       "  'kick',\n",
       "  'thursday',\n",
       "  'morning',\n",
       "  'citrus',\n",
       "  'center',\n",
       "  'kiwani',\n",
       "  'pleasure',\n",
       "  'catch',\n",
       "  'president',\n",
       "  'nan',\n",
       "  'clark',\n",
       "  'amp',\n",
       "  'president',\n",
       "  'elect',\n",
       "  'kathryn',\n",
       "  'koch',\n",
       "  'mingle',\n",
       "  'member',\n",
       "  'thank',\n",
       "  'let',\n",
       "  'join',\n",
       "  'today',\n",
       "  'flapol',\n",
       "  'fl',\n",
       "  'kiwani'],\n",
       " ['happen',\n",
       "  'today',\n",
       "  'join',\n",
       "  'grand',\n",
       "  'opening',\n",
       "  'satellite',\n",
       "  'district',\n",
       "  'office',\n",
       "  'brandonriverview',\n",
       "  'today',\n",
       "  'pm',\n",
       "  'information',\n",
       "  'link',\n",
       "  'flapol',\n",
       "  'fl'],\n",
       " ['range', 'alafia', 'river', 'use', 'caution', 'flapol', 'fl', 'alafiariver'],\n",
       " ['be',\n",
       "  'deeply',\n",
       "  'sadden',\n",
       "  'hear',\n",
       "  'passing',\n",
       "  'councilman',\n",
       "  'ray',\n",
       "  'goodgame',\n",
       "  'clermont',\n",
       "  'outstanding',\n",
       "  'leader',\n",
       "  'community',\n",
       "  'deeply',\n",
       "  'miss',\n",
       "  'thought',\n",
       "  'prayer',\n",
       "  'family',\n",
       "  'difficult',\n",
       "  'time'],\n",
       " ['live',\n",
       "  'east',\n",
       "  'hillsborough',\n",
       "  'area',\n",
       "  'join',\n",
       "  'grand',\n",
       "  'opening',\n",
       "  'satellite',\n",
       "  'district',\n",
       "  'office',\n",
       "  'brandonriverview',\n",
       "  'thursday',\n",
       "  'pm',\n",
       "  'information',\n",
       "  'flapol',\n",
       "  'fl'],\n",
       " ['thank',\n",
       "  'have',\n",
       "  'appreciate',\n",
       "  'insight',\n",
       "  'legislation',\n",
       "  'impact',\n",
       "  'trucking',\n",
       "  'industry',\n",
       "  'shortage',\n",
       "  'truck',\n",
       "  'driver',\n",
       "  'nationwide',\n",
       "  'longtime',\n",
       "  'supporter',\n",
       "  'vocationaltechnical',\n",
       "  'training',\n",
       "  'awesome',\n",
       "  'experience'],\n",
       " ['great',\n",
       "  'morning',\n",
       "  'coca',\n",
       "  'cola',\n",
       "  'fabulous',\n",
       "  'lunch',\n",
       "  'world',\n",
       "  'war',\n",
       "  'ii',\n",
       "  'hero',\n",
       "  'warrant',\n",
       "  'officer',\n",
       "  'randall',\n",
       "  'edward',\n",
       "  'celebrate',\n",
       "  'nd',\n",
       "  'birthday',\n",
       "  'thank',\n",
       "  'sir',\n",
       "  'live',\n",
       "  'life',\n",
       "  'worthy',\n",
       "  'follow'],\n",
       " ['motion',\n",
       "  'recommit',\n",
       "  'amend',\n",
       "  'minimum',\n",
       "  'wage',\n",
       "  'bill',\n",
       "  'amp',\n",
       "  'exempt',\n",
       "  'small',\n",
       "  'business',\n",
       "  'retain',\n",
       "  'few',\n",
       "  'employee',\n",
       "  'annual',\n",
       "  'gross',\n",
       "  'income',\n",
       "  'job',\n",
       "  'destroy',\n",
       "  'wage',\n",
       "  'hike',\n",
       "  'dem',\n",
       "  'vote',\n",
       "  'protect',\n",
       "  'small',\n",
       "  'business'],\n",
       " ['night',\n",
       "  'authorize',\n",
       "  'appropriation',\n",
       "  'fy',\n",
       "  'intel',\n",
       "  'amp',\n",
       "  'related',\n",
       "  'activity',\n",
       "  'today',\n",
       "  'vote',\n",
       "  'real',\n",
       "  'bad',\n",
       "  'legislation',\n",
       "  'want',\n",
       "  'double',\n",
       "  'min',\n",
       "  'wage',\n",
       "  'reverse',\n",
       "  'gain',\n",
       "  'economy',\n",
       "  'past',\n",
       "  'yrs',\n",
       "  'thought',\n",
       "  'find']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tweets = [prep.twitter_preprocess(tweet) for tweet in tweets]\n",
    "#tweets = [prep.replace_keyword(prep.key_tokens[0], tweet) for tweet in tweets[0:20]]\n",
    "#tweets = [prep.isolate_key_tokens(tweet) for tweet in tweets]\n",
    "tweets = [prep.tag_keywords('impeach', tweet, 'R') for tweet in tweets]\n",
    "\n",
    "#tweets = [prep.spacy_lemmatizer(tweet) for tweet in tweets[0:100]]\n",
    "tweets = prep.multi_lemmatizer(tweets[0:100], threads = 6)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at what point did due process become trump_R cosmetic in this country trump_R i dont remember that in law school trump_R'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individual test case for pipeline allowing me to test various manipulations\n",
    "test_text = '  At 123145 what point @ # () *||+=did due process become potus \"cosmetic\" in this country? #presidenttrump I dont remember that in law school. ðŸ¤” https://t.co/ew1hbvbWBj Donald Trump  '\n",
    "test_text = prep.twitter_preprocess(test_text)\n",
    "#test_text = multiple_replace('trump', test_text)\n",
    "test_text = prep.tag_keywords('trump', test_text, 'R')\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_list)):\n",
    "    text_list[i] = re.sub(token, token + \"_\" + tag_list[i], text_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump',\n",
       " 'president',\n",
       " 'healthcare',\n",
       " 'border',\n",
       " 'wall',\n",
       " 'democrat',\n",
       " 'republican',\n",
       " 'liberal',\n",
       " 'conservative',\n",
       " 'abortion',\n",
       " 'clinton',\n",
       " 'sanders',\n",
       " 'socialist',\n",
       " 'economy',\n",
       " 'jobs',\n",
       " 'impeach',\n",
       " 'obama',\n",
       " 'russia',\n",
       " 'mueller',\n",
       " 'collusion',\n",
       " 'military',\n",
       " 'budget',\n",
       " 'market',\n",
       " 'trade',\n",
       " 'vote',\n",
       " 'democracy',\n",
       " 'gun',\n",
       " 'agriculture',\n",
       " 'women',\n",
       " 'business',\n",
       " 'tax',\n",
       " 'medicare',\n",
       " 'police',\n",
       " 'immigration',\n",
       " 'insurance',\n",
       " 'climatechange',\n",
       " 'corrupt',\n",
       " 'electoralcollege',\n",
       " 'judge',\n",
       " 'court',\n",
       " 'gerrymander',\n",
       " 'pelosi',\n",
       " 'mcconnell',\n",
       " 'mikepence',\n",
       " 'citizensunited',\n",
       " 'daca',\n",
       " 'dreamers',\n",
       " 'lgbtq',\n",
       " 'ACA',\n",
       " 'scotus',\n",
       " 'partisan',\n",
       " 'patriot',\n",
       " 'welfare',\n",
       " 'privilege',\n",
       " 'minority',\n",
       " 'islam',\n",
       " 'muslim',\n",
       " 'christian',\n",
       " 'god',\n",
       " 'religion',\n",
       " 'administration',\n",
       " 'politics',\n",
       " 'fair',\n",
       " 'witchhunt',\n",
       " 'warren',\n",
       " 'biden',\n",
       " 'security',\n",
       " 'terrorism',\n",
       " 'defense',\n",
       " 'pentagon',\n",
       " 'homelandsecurity',\n",
       " 'senate',\n",
       " 'wealth',\n",
       " 'american',\n",
       " 'church',\n",
       " 'science',\n",
       " 'stockmarket',\n",
       " 'congress',\n",
       " 'whitehouse',\n",
       " 'constitution',\n",
       " 'federal',\n",
       " 'syria',\n",
       " 'northkorea',\n",
       " 'saudiarabia',\n",
       " 'mexico',\n",
       " 'debt',\n",
       " 'fiscal',\n",
       " 'oil',\n",
       " 'media',\n",
       " 'cnn',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'racist',\n",
       " 'refugee',\n",
       " 'education',\n",
       " 'maga',\n",
       " 'campaign',\n",
       " 'party',\n",
       " 'poll']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.key_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('C:/Users/Mike/Desktop/word_embeddings-master') # windows dir\n",
    "os.chdir('/home/mike/Desktop/Word Embeddings') # linux dir\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "os.chdir('./Text Processing')\n",
    "from TextPrep import TextPrep\n",
    "from get_cosine import cosine_sim\n",
    "os.chdir('..')\n",
    "\n",
    "os.chdir('./Meta Data')\n",
    "from key_words import key_words, key_synonyms, agree_words, agree_synonyms, base_words, base_synonyms\n",
    "from stop_words import stop_words\n",
    "os.chdir('..')\n",
    "\n",
    "# set the number of threads\n",
    "n_threads = 1\n",
    "\n",
    "# set the number of permutations to run\n",
    "permutations = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('Data/replication_text.csv')\n",
    "# Create lists of text and labels\n",
    "tweets = tweet_df['text']\n",
    "labels = tweet_df['party']\n",
    "\n",
    "# initialize parser for both keywords and base words\n",
    "keyprep = TextPrep(stopwords = stop_words, key_words = key_words, key_synonyms = key_synonyms)\n",
    "baseprep = TextPrep(stopwords = stop_words, key_words = base_words, key_synonyms = base_synonyms)\n",
    "agreeprep = TextPrep(stopwords = stop_words, key_words = agree_words, key_synonyms = agree_synonyms)\n",
    "\n",
    "# preprocess text\n",
    "tweets = [keyprep.twitter_preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize text parser and pre-process tweets\n",
    "prep = TextPrep(stopwords = stop_words, key_words = base_words, key_synonyms = base_synonyms)\n",
    "tweets = [prep.twitter_preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7h 27min 8s, sys: 24min 7s, total: 7h 51min 15s\n",
      "Wall time: 5h 40min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sim = []\n",
    "for i in range(permutations):\n",
    "    # permute the labels\n",
    "    rlabels = random.sample(list(labels), len(labels))\n",
    "    # Get cosine similarity\n",
    "    rcosine = cosine_sim(parser = prep, keyword = 'place', text = tweets, labels = rlabels, threads = n_threads)\n",
    "    # append to list\n",
    "    sim.append(rcosine)\n",
    "\n",
    "# save results as a csv\n",
    "simdf = pd.DataFrame(sim, columns = ['cosine similarity'])\n",
    "simdf.to_csv('place_permutation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as a csv\n",
    "#simdf = pd.DataFrame(sim, columns = ['cosine similarity'])\n",
    "#simdf.to_csv('Analysis/permutation.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

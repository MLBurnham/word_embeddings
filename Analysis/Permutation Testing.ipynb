{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/Mike/Desktop/word_embeddings-master') # windows dir\n",
    "# os.chdir('/home/mike/Desktop/Word Embeddings') # linux dir\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "os.chdir('./Text Processing')\n",
    "from TextPrep import TextPrep\n",
    "\n",
    "os.chdir('../Meta Data')\n",
    "from key_words import key_words, key_synonyms\n",
    "from stop_words import stop_words\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for getting cosine similarity\n",
    "# variables needed: keyword, list of tweets, list of labels, tagged keywords\n",
    "# unsure if I want most similar words or not\n",
    "# adjust number of threads, add variable to toggle multithreading\n",
    "\n",
    "def cosine_sim(keyword, text, labels):\n",
    "    # define tagged keywords. To generalize get a list of unique labels. loop through create a new variable for each label\n",
    "    keyword_r = keyword + '_r'\n",
    "    keyword_d = keyword + '_d'\n",
    "    \n",
    "    ptweets = []\n",
    "    for i in range(len(text)):\n",
    "        try:\n",
    "            ptweets.append(prep.tag_keywords(keyword, text[i], labels[i])) # tweets and labels are global variables. change to local\n",
    "        except:\n",
    "            print('failed at '+ str(i))\n",
    "\n",
    "    # lemmatize\n",
    "    ptweets = prep.multi_lemmatizer(ptweets, threads = 8)\n",
    "\n",
    "    # drop single letters\n",
    "    for i in range(len(ptweets)):\n",
    "        ptweets[i] = [word for word in ptweets[i] if len(word) > 1]\n",
    "\n",
    "    # train and save word2vec\n",
    "    pmodel = Word2Vec(ptweets, window = 10, sg = 1)\n",
    "\n",
    "    # assign data to variables\n",
    "    psim = pmodel.wv.similarity(keyword_r, keyword_d)\n",
    "    return psim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "meta_data = pd.read_csv('Meta Data/meta_data.csv')\n",
    "tweet_df = pd.read_csv('Data/aggregated_tweets.csv')\n",
    "# subset to tweets after oct 29\n",
    "tweet_df = tweet_df[tweet_df['created'] >= '2019-11-06']\n",
    "# merge data with meta data\n",
    "tweet_df = pd.merge(tweet_df, meta_data, how = 'inner', on = 'user_id')\n",
    "tweet_df = tweet_df[tweet_df.party.isin(['R', 'D'])].reset_index(drop=True)\n",
    "\n",
    "tweets = tweet_df['text']\n",
    "plabels = tweet_df['party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize twitter processor and pre-process tweets\n",
    "prep = TextPrep(stopwords = stop_words, key_words = key_words, key_synonyms = key_synonyms)\n",
    "tweets = [prep.twitter_preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15h 14min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run the permutation test\n",
    "sim = []\n",
    "for i in range(1000):\n",
    "    # permute the labels\n",
    "    rlabels = random.sample(list(plabels), len(plabels))\n",
    "    # Get cosine similarity\n",
    "    rcosine = cosine_sim(keyword = 'trump', text = tweets, labels = rlabels)\n",
    "    # append to list\n",
    "    sim.append(rcosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as a csv\n",
    "simdf = pd.DataFrame(sim, columns = ['cosine similarity'])\n",
    "simdf.to_csv('Analysis/permutation.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

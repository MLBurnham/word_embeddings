{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/mike/Desktop/Word Embeddings')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "os.chdir('./Text Processing')\n",
    "from TextPrep import TextPrep\n",
    "\n",
    "os.chdir('../Meta Data')\n",
    "from key_words import key_words_small, key_synonyms, base_words, base_synonyms\n",
    "from stop_words import stop_words\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for analyzing the word vectors\n",
    "\n",
    "# gets most similar words\n",
    "def similar_words(word, model, topn):\n",
    "    sim_words = []\n",
    "    for i in range(topn):\n",
    "        sim_words.append(model.wv.most_similar(word, topn = topn)[i][0])\n",
    "    return sim_words + [word]\n",
    "\n",
    "# returns a dictionary for the similar words. values are the key words, keys are the most similar words\n",
    "def similar_dict(words1, words2, labels):\n",
    "    both = [word for word in words1 if word in words2]\n",
    "    words1 = [word for word in words1 if word not in both]\n",
    "    words2 = [word for word in words2 if word not in both]\n",
    "    words = [words1, words2, both]\n",
    "    labels = labels + ['Both']\n",
    "    dictionary = {}\n",
    "    for i in range(len(labels)):\n",
    "        for word in words[i]:\n",
    "            dictionary[word] = labels[i]\n",
    "    return dictionary\n",
    "\n",
    "# Converts pca model to a data frame for plotting\n",
    "def pca2df(pcamodel, embedding, dictionary):\n",
    "    # convert the pca element to a df\n",
    "    pc_df = pd.DataFrame(data = pcamodel, columns = ['pc1', 'pc2', 'pc3'])\n",
    "    # add word column to the df\n",
    "    pc_df['word'] = [key for key in embedding.wv.vocab]\n",
    "    # get a list of unique words from the dictionary\n",
    "    words = list(dictionary.keys())\n",
    "    words = list(set(words))\n",
    "    # keep only components that are in the list of unique words\n",
    "    pc_df = pc_df[pc_df['word'].isin(words)].reset_index(drop=True)\n",
    "    colors = {'Democrat': 'blue', 'Republican':'red', 'Both': 'purple', 'A': 'blue', 'B':'red'}\n",
    "    pc_df['label'] = pc_df['word'].map(dictionary)\n",
    "    pc_df['color'] = [colors[word] for word in pc_df['label']]\n",
    "    return pc_df\n",
    "\n",
    "# returns the cosine similarity of two words\n",
    "def cosine_sim(parser, keyword, text, labels):\n",
    "    # define tagged keywords. To generalize get a list of unique labels. loop through create a new variable for each label\n",
    "    keyword_r = keyword + '_r'\n",
    "    keyword_d = keyword + '_d'\n",
    "    \n",
    "    ptweets = []\n",
    "    for i in range(len(text)):\n",
    "        try:\n",
    "            ptweets.append(parser.tag_keywords(keyword, text[i], labels[i])) # tweets and labels are global variables. change to local\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('failed at '+ keyword + str(i))\n",
    "            \n",
    "\n",
    "    # lemmatize\n",
    "    ptweets = parser.multi_lemmatizer(ptweets, threads = 6)\n",
    "\n",
    "    # drop single letters\n",
    "    for i in range(len(ptweets)):\n",
    "        ptweets[i] = [word for word in ptweets[i] if len(word) > 1]\n",
    "\n",
    "    # train and save word2vec\n",
    "    pmodel = Word2Vec(ptweets, window = 10, sg = 1)\n",
    "    \n",
    "    # return cosine similarity between the words\n",
    "    return pmodel.wv.similarity(keyword_r, keyword_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "meta_data = pd.read_csv('Meta Data/meta_data.csv')\n",
    "tweet_df = pd.read_csv('Data/aggregated_tweets.csv')\n",
    "# subset to tweets after oct 29\n",
    "tweet_df = tweet_df[tweet_df['created'] >= '2019-11-06']\n",
    "# merge data with meta data\n",
    "tweet_df = pd.merge(tweet_df, meta_data, how = 'inner', on = 'user_id')\n",
    "tweet_df = tweet_df[tweet_df.party.isin(['R', 'D'])].reset_index(drop=True)\n",
    "\n",
    "tweets = tweet_df['text']\n",
    "labels = tweet_df['party']\n",
    "\n",
    "# initialize parser for both keywords and base words\n",
    "keyprep = TextPrep(stopwords = stop_words, key_words = key_words_small, key_synonyms = key_synonyms)\n",
    "baseprep = TextPrep(stopwords = stop_words, key_words = base_words, key_synonyms = base_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 598 ms, sys: 487 Âµs, total: 598 ms\n",
      "Wall time: 597 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess text\n",
    "tweets = [keyprep.twitter_preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cosine sim for key and base words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 14 s, total: 4min 39s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get cosine similarity for all words in the key word list\n",
    "keysim = []\n",
    "for word in key_words_small[0:5]:\n",
    "    cosine = cosine_sim(parser = keyprep, keyword = word, text = tweets, labels = labels)\n",
    "    keysim.append(cosine)\n",
    "\n",
    "# Convert to dataframe\n",
    "keysimdf = pd.DataFrame(data=list(zip(key_words_small[0:5], keysim)), columns = ['word', 'similarity'])\n",
    "keysimdf.to_csv('keyword_similarity.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get cosine similarity for all words in the base word list\n",
    "basesim = []\n",
    "for word in base_words[0:5]:\n",
    "    cosine = cosine_sim(parser = baseprep, keyword = word, text = tweets, labels = labels)\n",
    "    basesim.append(cosine)\n",
    "\n",
    "# Convert to dataframe\n",
    "basesimdf = pd.DataFrame(data=list(zip(base_words[0:5], basesim)), columns = ['word', 'similarity'])\n",
    "basesimdf.to_csv('baseword_similarity.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'administration' in prep.key_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im live this morning on kfor with laceylett great talk on reducing prescription drug costs and my upcoming community conversations in oklahoma\n"
     ]
    }
   ],
   "source": [
    "if 'administration' in prep.key_synonyms:\n",
    "    print(prep.replace_synonyms('administration', tweets[0]))\n",
    "print(tweets[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

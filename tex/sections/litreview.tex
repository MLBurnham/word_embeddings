\documentclass[../embeddings.tex]{subfiles}
 
\begin{document}
In this section I first briefly review the literature on what techniques political scientists currently use to leverage text as data. I then give a brief overview of what word embeddings are and the theoretical validation for their use. Finally, I examine some of the recent developments in leveraging word embeddings that I hope to build on with this research.

\subsection{Classification and scaling}
Social scientists have largely relied on what is known as a bag-of-words method for NLP tasks. Bag of words methods analyze text by treating documents as unorganized collections of words, counting the instances of words within a text, and using those word counts to infer meaning or make predictions \cite{monroe2008introduction}. Counted words may be part of a pre-compiled list of significant terms such as the Dictionary of Affect in Language \cite{whissell2009using} or Linguistic Inquiry and Word Count \cite{pennebaker2001linguistic} which are used to count words associated with sentiment or  certain emotions, or they may follow some unsupervised algorithm that assigns weights to all words and analyzes text best and the words and their associated weights that appear in a text. Wordfish and Wordscores are two commonly used pieces of software that rely on a bag-of-words approach to classify documents \cite{proksch2008wordfish, laver2003extracting}.

The primary shortcoming of this method is that it ignores context and assumes each word is an independent observation \cite{bruinsma2017validating, monroe2008introduction}. The phrase “not bad”, for example, could mean anything from mild criticism to strong praise depending on the context in which it is used. Yet, a bag of words approach only sees the words “not” and “bad” which, if doing sentiment analysis, will always count as two negative words within the document. This is somewhat alleviated by what’s known as n-grams, or a window of n words that treats all words within that window as a single observation. However, n-grams still ignore larger sentence structure, multiply the number of unique features in your data set by n, and maintains the naive assumption that there is no relationship between features. 

These shortcomings mean that bag-of-words approaches tend to be noisy. Wordscores, for example, has a tendency to overweight high-frequency words and does not account well for sampling variation \cite{monroe2008fightin, lowe2008understanding}. Wordfish, on the other hand, suffers from interpretability challenges. Because the algorithm is unsupervised and places documents on a single dimension that is defined by the algorithm rather than the researcher, it is not necessarily the case that the dimension is related to the topic of interest. Wordfish may capture sentiment rather than party affiliation, for example. Because both methods depend on word frequencies, both techniques struggle with unique or low frequency words even though low frequency words may be particularly informative to a human reader. In modern applications, bag-of-words approaches are used because they are computationally cheap. They are rarely, if ever, the most robust approach to an NLP task.

\subsection{Word embeddings and the distributional hypothesis}
Popularized in 2013 by Google’s Word2vec algorithm, word embeddings greatly alleviate many shortcomings of the bag-of-words approach \cite{mikolov2013efficient}. Speaking broadly, word embeddings are language models in which each word is represented by a vector of numbers. The most basic algorithm works by observing a corpus of documents and noting which words appear together. With enough observations, a predictive model is able to determine which word is most likely to appear based on its surrounding words, or vice versa. The series of numbers that is fed to this model to predict a word is known as a word vector \cite{goldberg2014word2vec}. Each word in the data set has a word vector representation, and the collection of these word vectors is the word embedding.

Word embeddings have proven particularly adept at modeling language and form the backbone of modern NLP. Word vectors are able to capture sentiment, part of speech, or even abstract concepts associated with a word. Thus, word vectors do not just represent a word, but the conceptual and semantic ideas a word represents. A famous example is that the word vector for queen is roughly equal to the vector for king, minus the vector for man, plus the vector for woman. That is:
\begin{equation}
Queen = King – Man + Woman
\end{equation}
While this example serves little practical purpose, it does demonstrate surprising capacity of embeddings. To explain further, word embeddings are able to recognize that the concept of “king” is defined by a political position and the male gender. If I take the vector of numbers that represents king, subtract the vector for man, add the vector for woman, the resulting vector is defined by political position and the female gender. As expected, the nearest neighbor to my new vector is the vector that represents queen. Numeric representations of semantic concepts allow us to plot them in high dimensional space, calculate the distance or similarity between concepts, and even preform mathematical operations with them.

\subsection{Use of word embeddings to measure semantic differences}
Within industry and academia, word embeddings are primarily used to boost the performance of machine learning algorithms on natural language processing tasks. This trend has largely carried over in to political science. Rudkowsky et al., for example, used word embeddings to boost the performance of an algorithm that labels the sentiment of Austrian parliamentary speeches \cite{rudkowsky2018more}. Likewise, Iyyer et al. use word embeddings and recursive neural networks to assign binary ideological labels to political text \cite{iyyer2014political}. Using embeddings to boost the performance of algorithms is certainly an important and worthy area of research. It is particularly useful in political science when categorical labels such as party affiliation or sentiment need to be estimated for a data set. 

However, word embeddings are rich in semantic information and are worth examination as a language model themselves rather than being relegated solely to feeding algorithms. The foundation of word embeddings is known as the distributional hypothesis. The distributional hypothesis states that words appearing in similar contexts have similar meanings \cite{goldberg2014word2vec, mikolov2013efficient}. Intuitively, this makes sense – synonyms such as table and desk are likely to appear next to similar words. Therefore, their numeric vectors will be similar and if we were to calculate the distance between these vectors, table would be closer to desk than queen. 

For our purposes, the strength of word embeddings is directly tied to the distributional hypothesis. If the hypothesis holds, the converse is also true. Namely, that dissimilar words are found in dissimilar contexts. By extension, if two groups use the same word in different contexts, the two groups are assigning different meanings to the word. These differences in meanings can be used to represent ideological differences. For example, a word embedding training on conservative texts may find that the word vector for abortion is mathematically closer words like “murder” and “baby” than it is to words like “woman” and “choice” while the converse is true for an embedding trained on liberal texts. These mathematical differences between word vectors represent ideological fault lines between groups.

In recent years, two groups of researchers made significant strides with using word embeddings for measuring semantic differences. Hamilton et al. leveraged word embeddings to examine semantic changes across the dimension of time \cite{hamilton2016diachronic}. Their technique uses text associated with specific time periods to create embeddings across time. Because different word embeddings occupy different vector spaces however, it is impossible to calculate distance between words directly. To get around this, the authors utilize orthogonal procrustes analysis which, roughly speaking, finds a matrix that most closely aligns the two embeddings, allowing them to compare across vector space. In doing so, they successfully demonstrated the evolution of a words semantic meaning across time.

Azarbonyad et al. advanced this technique by replacing the dimension of time with “viewpoints.” To test the method, they used text from the UK parliament to examine words to examine words where they expected ideological convergence and divergence \cite{azarbonyad2017words}. In both instances they found that word vectors diverged where ideological differences were expected and converged on words where no differences were expected.

\end{document}